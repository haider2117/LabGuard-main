# Camera-Based Monitoring Module - Implementation Tasks

## Overview

This document tracks all implementation tasks for the camera-based monitoring module. Tasks are organized by phase and can be checked off as they are completed.

**Status Legend**:
- ‚¨ú Not Started
- üü° In Progress
- ‚úÖ Completed
- ‚ùå Blocked/Cancelled

---

## Phase 1: Python Backend (Core ML/CV)

### 1.1 Project Structure Setup
- [‚úÖ] Create `backend/camera_monitoring/` directory
- [‚úÖ] Create `backend/camera_monitoring/detectors/` directory
- [‚úÖ] Create `backend/camera_monitoring/models/` directory
- [‚úÖ] Create `backend/camera_monitoring/utils/` directory
- [‚úÖ] Create `__init__.py` files in all Python packages
- [‚úÖ] Create `python_requirements.txt` with dependencies
- [‚úÖ] Create `.gitkeep` in `models/` directory

### 1.2 Configuration Module
- [‚úÖ] Create `backend/camera_monitoring/config.py`
- [‚úÖ] Define detection thresholds (phone, person confidence)
- [‚úÖ] Define gaze thresholds (left, right, center)
- [‚úÖ] Define blink detection thresholds (EAR)
- [‚úÖ] Define head pose ranges (facing screen)
- [‚úÖ] Define camera settings (width, height, FPS)
- [‚úÖ] Define model paths
- [‚úÖ] Add performance settings (frame skip, GPU enable)

### 1.3 Object Detector (YOLOv8n)
- [‚úÖ] Create `backend/camera_monitoring/detectors/object_detector.py`
- [‚úÖ] Implement `load_model(model_path)` method
- [‚úÖ] Implement `detect(frame)` method
- [‚úÖ] Implement phone detection filtering (class 67)
- [‚úÖ] Implement person counting (class 0)
- [‚úÖ] Return bounding boxes and confidence scores
- [‚úÖ] Add error handling for model loading
- [‚úÖ] Test with sample images (test script created)
- [‚úÖ] Download YOLOv8n model to `models/yolov8n.pt` (auto-downloads on first use)

### 1.4 Face Analyzer (MediaPipe)
- [‚úÖ] Create `backend/camera_monitoring/detectors/face_analyzer.py`
- [‚úÖ] Implement `initialize()` method (setup MediaPipe)
- [‚úÖ] Implement `detect_face(frame)` method
- [‚úÖ] Extract 468 facial landmarks
- [‚úÖ] Implement `calculate_head_pose(landmarks)` method
- [‚úÖ] Implement `get_iris_positions(landmarks)` method
- [‚úÖ] Return face detection status, landmarks, head pose
- [‚úÖ] Add error handling for MediaPipe initialization
- [‚úÖ] Test with sample images/video

### 1.5 Gaze Estimator
- [‚úÖ] Create `backend/camera_monitoring/detectors/gaze_estimator.py`
- [‚úÖ] Implement `estimate_gaze(iris_positions, head_pose)` method
- [‚úÖ] Calculate horizontal gaze angle
- [‚úÖ] Classify gaze direction (left/center/right)
- [‚úÖ] Implement `calculate_ear(eye_landmarks)` method
- [‚úÖ] Implement `detect_blink(ear, threshold)` method
- [‚úÖ] Implement `is_facing_screen(head_pose)` method
- [‚úÖ] Return gaze direction, blink status, screen-facing status
- [‚úÖ] Test with sample data

### 1.6 Geometry Utilities
- [‚úÖ] Create `backend/camera_monitoring/utils/geometry.py`
- [‚úÖ] Implement head pose calculation helpers
- [‚úÖ] Implement coordinate transformation functions
- [‚úÖ] Implement angle calculation functions
- [‚úÖ] Implement distance measurement functions
- [‚úÖ] Add unit tests for geometry functions

### 1.7 Main Camera Processor
- [‚úÖ] Create `backend/camera_monitoring/camera_processor.py`
- [‚úÖ] Implement `initialize()` method (camera + models)
- [‚úÖ] Implement `process_frame(frame)` method
- [‚úÖ] Integrate all detectors (object, face, gaze)
- [‚úÖ] Implement main processing loop
- [‚úÖ] Implement JSON status output to stdout
- [‚úÖ] Implement error handling and logging
- [‚úÖ] Implement graceful shutdown (SIGTERM handler)
- [‚úÖ] Add FPS calculation and reporting
- [‚úÖ] Test standalone with webcam

### 1.8 Python Dependencies Setup
- [‚¨ú] Create `python_requirements.txt` with all dependencies
- [‚¨ú] Test Python environment setup
- [‚¨ú] Verify OpenCV installation
- [‚¨ú] Verify MediaPipe installation
- [‚¨ú] Verify Ultralytics installation
- [‚¨ú] Test model loading (YOLOv8n, MediaPipe)
- [‚¨ú] Test camera access

---

## Phase 2: Node.js Integration

### 2.1 Camera Monitoring Service
- [‚¨ú] Create `backend/services/cameraMonitoringService.js`
- [‚¨ú] Implement `startMonitoring()` method (spawn Python)
- [‚¨ú] Implement `stopMonitoring()` method (kill Python)
- [‚¨ú] Implement stdout parser (JSON parsing)
- [‚¨ú] Implement error handling for Python process
- [‚¨ú] Implement IPC event forwarding to renderer
- [‚¨ú] Add process lifecycle management
- [‚¨ú] Add logging for debugging
- [‚¨ú] Test Python subprocess communication

### 2.2 Electron IPC Handlers
- [‚¨ú] Add `camera:start-test` IPC handler in `backend/app/main.js`
- [‚¨ú] Add `camera:stop-test` IPC handler
- [‚¨ú] Add `camera:get-status` IPC handler
- [‚¨ú] Implement `camera:status-update` event emission
- [‚¨ú] Add error handling for IPC calls
- [‚¨ú] Test IPC communication

### 2.3 Preload Script Updates
- [‚¨ú] Update `backend/app/preload.js` with camera IPC methods
- [‚¨ú] Expose `camera.startTest()` method
- [‚¨ú] Expose `camera.stopTest()` method
- [‚¨ú] Expose `camera.getStatus()` method
- [‚¨ú] Expose `camera.onStatusUpdate()` event listener
- [‚¨ú] Test preload script functionality

### 2.4 Setup Script
- [‚¨ú] Create `backend/scripts/setup-camera-monitoring.js`
- [‚¨ú] Check Python installation
- [‚¨ú] Check Python version (3.9-3.11)
- [‚¨ú] Install Python dependencies from `python_requirements.txt`
- [‚¨ú] Download YOLOv8n model if missing
- [‚¨ú] Verify MediaPipe installation
- [‚¨ú] Test camera access
- [‚¨ú] Create necessary directories
- [‚¨ú] Add error messages and user guidance

### 2.5 Package.json Updates
- [‚¨ú] Add `setup-camera` script to `package.json`
- [‚¨ú] Add `test-camera` script to `package.json`
- [‚¨ú] Update `postinstall` script to run setup (optional)
- [‚¨ú] Document new scripts in README

---

## Phase 3: Frontend UI

### 3.1 Camera Test Module Component
- [‚¨ú] Create `frontend/src/components/CameraTestModule.tsx`
- [‚¨ú] Implement component state management
- [‚¨ú] Implement IPC communication (start/stop)
- [‚¨ú] Implement status update event listener
- [‚¨ú] Implement error handling
- [‚¨ú] Add loading states
- [‚¨ú] Test component rendering

### 3.2 Camera Display Component
- [‚¨ú] Create `frontend/src/components/CameraMonitorDisplay.tsx`
- [‚¨ú] Implement video element for camera feed
- [‚¨ú] Implement canvas overlay for bounding boxes
- [‚¨ú] Draw phone detection boxes
- [‚¨ú] Draw person detection boxes
- [‚¨ú] Draw head pose indicators (arrows)
- [‚¨ú] Draw gaze direction indicator
- [‚¨ú] Add text labels for detections
- [‚¨ú] Optimize canvas rendering (throttle updates)
- [‚¨ú] Test overlay rendering

### 3.3 Status Panel
- [‚¨ú] Create status panel UI in `CameraTestModule.tsx`
- [‚¨ú] Display phone detection status (‚úÖ/‚ùå)
- [‚¨ú] Display person count
- [‚¨ú] Display head pose angles (yaw, pitch, roll)
- [‚¨ú] Display gaze direction (left/center/right)
- [‚¨ú] Display blink status
- [‚¨ú] Display FPS counter
- [‚¨ú] Add visual indicators (icons, colors)
- [‚¨ú] Style status panel

### 3.4 Violation Log
- [‚¨ú] Create violation log component
- [‚¨ú] Display violation events with timestamps
- [‚¨ú] Format violation messages
- [‚¨ú] Add scrollable list
- [‚¨ú] Add clear log button
- [‚¨ú] Color-code violation types
- [‚¨ú] Style violation log

### 3.5 Control Buttons
- [‚¨ú] Add "Start Monitoring" button
- [‚¨ú] Add "Stop Monitoring" button
- [‚¨ú] Implement button click handlers
- [‚¨ú] Add loading states to buttons
- [‚¨ú] Disable buttons during transitions
- [‚¨ú] Style control buttons

### 3.6 Styling
- [‚¨ú] Create `frontend/src/components/CameraTestModule.css`
- [‚¨ú] Style camera display area
- [‚¨ú] Style status panel
- [‚¨ú] Style violation log
- [‚¨ú] Style control buttons
- [‚¨ú] Add responsive design
- [‚¨ú] Match LabGuard design system

### 3.7 Login Screen Integration
- [‚¨ú] Add "Test Camera Module" button to `Login.tsx`
- [‚¨ú] Implement button click handler
- [‚¨ú] Open `CameraTestModule` in modal or new view
- [‚¨ú] Handle modal/view closing
- [‚¨ú] Style button to match login screen
- [‚¨ú] Test button visibility and functionality

### 3.8 Error Handling UI
- [‚¨ú] Display camera access denied error
- [‚¨ú] Display model loading error
- [‚¨ú] Display Python process error
- [‚¨ú] Display IPC communication error
- [‚¨ú] Add retry buttons for errors
- [‚¨ú] Style error messages

---

## Phase 4: Testing & Refinement

### 4.1 Unit Testing
- [‚¨ú] Write unit tests for `object_detector.py`
- [‚¨ú] Write unit tests for `face_analyzer.py`
- [‚¨ú] Write unit tests for `gaze_estimator.py`
- [‚¨ú] Write unit tests for `geometry.py`
- [‚¨ú] Write unit tests for `cameraMonitoringService.js`
- [‚¨ú] Run all unit tests
- [‚¨ú] Fix failing tests

### 4.2 Integration Testing
- [‚¨ú] Test Python ‚Üí Node.js communication
- [‚¨ú] Test Node.js ‚Üí Frontend IPC
- [‚¨ú] Test end-to-end flow (button click ‚Üí camera feed)
- [‚¨ú] Test error scenarios (camera denied, model missing)
- [‚¨ú] Test process lifecycle (start, stop, restart)
- [‚¨ú] Fix integration issues

### 4.3 Manual Testing Scenarios
- [‚¨ú] Test: No violations (normal scenario)
- [‚¨ú] Test: Phone in frame
- [‚¨ú] Test: Multiple persons
- [‚¨ú] Test: Looking away from screen
- [‚¨ú] Test: No face detected
- [‚¨ú] Test: All violations simultaneously
- [‚¨ú] Test: Camera access denied
- [‚¨ú] Test: Python process crash recovery
- [‚¨ú] Test: Long-running session (1+ hour)
- [‚¨ú] Document test results

### 4.4 Performance Optimization
- [‚¨ú] Measure FPS on target hardware
- [‚¨ú] Optimize frame processing (if < 20 FPS)
- [‚¨ú] Implement frame skipping if needed
- [‚¨ú] Optimize canvas rendering
- [‚¨ú] Reduce memory usage if > 2 GB
- [‚¨ú] Reduce CPU usage if > 50%
- [‚¨ú] Profile and identify bottlenecks
- [‚¨ú] Apply optimizations

### 4.5 Accuracy Tuning
- [‚¨ú] Test phone detection accuracy
- [‚¨ú] Tune phone confidence threshold
- [‚¨ú] Test person counting accuracy
- [‚¨ú] Test head pose accuracy
- [‚¨ú] Tune head pose ranges
- [‚¨ú] Test gaze direction accuracy
- [‚¨ú] Tune gaze thresholds
- [‚¨ú] Test blink detection accuracy
- [‚¨ú] Tune blink EAR threshold
- [‚¨ú] Document final thresholds

### 4.6 Error Handling Refinement
- [‚¨ú] Test all error scenarios
- [‚¨ú] Improve error messages
- [‚¨ú] Add recovery mechanisms
- [‚¨ú] Add retry logic where appropriate
- [‚¨ú] Test error handling under stress

### 4.7 Documentation
- [‚¨ú] Document Python API (docstrings)
- [‚¨ú] Document Node.js service API
- [‚¨ú] Document frontend component props
- [‚¨ú] Create user guide for test module
- [‚¨ú] Update README with camera module info
- [‚¨ú] Document configuration options
- [‚¨ú] Document troubleshooting steps

---

## Phase 5: Integration into Student Exam Flow (Future)

### 5.1 Remove Test Button
- [‚¨ú] Hide "Test Camera Module" button in production
- [‚¨ú] Add feature flag for test mode
- [‚¨ú] Or remove button entirely

### 5.2 Exam Page Integration
- [‚¨ú] Integrate camera monitoring into `ExamPage.tsx`
- [‚¨ú] Start monitoring when exam starts
- [‚¨ú] Stop monitoring when exam ends
- [‚¨ú] Display camera feed during exam (optional)
- [‚¨ú] Show violation warnings to student

### 5.3 Database Logging
- [‚¨ú] Create database schema for camera violations
- [‚¨ú] Implement violation logging service
- [‚¨ú] Log phone detections to database
- [‚¨ú] Log multiple person events
- [‚¨ú] Log gaze violations
- [‚¨ú] Log head pose violations
- [‚¨ú] Include timestamps and durations

### 5.4 Teacher Violation Reports
- [‚¨ú] Create violation report UI for teachers
- [‚¨ú] Display camera violations in violation list
- [‚¨ú] Show violation timeline
- [‚¨ú] Add filters for violation types
- [‚¨ú] Export violation data

### 5.5 Production Hardening
- [‚¨ú] Add performance monitoring
- [‚¨ú] Add error tracking
- [‚¨ú] Add usage analytics
- [‚¨ú] Security audit
- [‚¨ú] Privacy compliance review

---

## Dependencies & Prerequisites

### Required Before Starting
- [‚¨ú] Python 3.9-3.11 installed or plan for embedded Python
- [‚¨ú] Webcam available for testing
- [‚¨ú] Node.js and Electron environment working
- [‚¨ú] Git repository access

### External Resources
- [‚¨ú] YOLOv8n model download (Ultralytics)
- [‚¨ú] MediaPipe models (auto-downloaded)
- [‚¨ú] Test images/videos for development

---

## Progress Tracking

### Overall Progress
- **Phase 1 (Python Backend)**: 58/65 tasks completed (89.2%)
- **Phase 2 (Node.js Integration)**: 0/20 tasks completed (0%)
- **Phase 3 (Frontend UI)**: 0/28 tasks completed (0%)
- **Phase 4 (Testing & Refinement)**: 0/25 tasks completed (0%)
- **Phase 5 (Future Integration)**: 0/15 tasks completed (0%)

**Total**: 58/126 tasks completed (46.0%)

### Current Phase
**Status**: In Progress  
**Active Phase**: Phase 1 - Python Backend (Sub-Phase 1.7 ‚úÖ Complete)

### Blockers
- None currently

### Notes
- Add notes here as implementation progresses
- Document any deviations from plan
- Record important decisions

---

## Quick Reference

### Key Files to Create
1. `backend/camera_monitoring/camera_processor.py`
2. `backend/camera_monitoring/detectors/object_detector.py`
3. `backend/camera_monitoring/detectors/face_analyzer.py`
4. `backend/camera_monitoring/detectors/gaze_estimator.py`
5. `backend/services/cameraMonitoringService.js`
6. `frontend/src/components/CameraTestModule.tsx`

### Key Commands
```bash
# Setup Python environment
npm run setup-camera

# Test Python script standalone
npm run test-camera

# Start development
npm run dev
```

### Testing Checklist
- [ ] Camera access works
- [ ] Models load successfully
- [ ] Phone detection works
- [ ] Person counting works
- [ ] Head pose estimation works
- [ ] Gaze direction works
- [ ] Blink detection works
- [ ] UI updates in real-time
- [ ] Violations are logged
- [ ] Error handling works

---

## Change Log

| Date | Changes | Author |
|------|---------|--------|
| 2024-01-15 | Initial tasks document created | LabGuard Team |

